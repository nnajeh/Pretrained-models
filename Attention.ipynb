{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9Yf+pwy2g+pwSZpLiCJ13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnajeh/Pretrained-models/blob/main/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "DxGxdNHwSIA8"
      },
      "source": [
        "#@title 1. Producing the Encoder Hidden States"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vREeRMCRypN"
      },
      "source": [
        "class EncoderLSTM(nn.Module):\r\n",
        "  def __init__(self, input_size, hidden_size, n_layers=1, drop_prob=0):\r\n",
        "    super(EncoderLSTM, self).__init__()\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "    self.n_layers = n_layers\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\r\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=drop_prob, batch_first=True)\r\n",
        "\r\n",
        "  # Forward the input sequence (words, images, etc) through the LSTM states \r\n",
        "  def forward(self, inputs, hidden):\r\n",
        "    # Embed input words\r\n",
        "    embedded = self.embedding(inputs)\r\n",
        "    \r\n",
        "    # Pass the embedded word vectors into LSTM and return all outputs\r\n",
        "    output, hidden = self.lstm(embedded, hidden)\r\n",
        "    return output, hidden\r\n",
        "\r\n",
        "  def init_hidden(self, batch_size=1):\r\n",
        "    return (torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "UxZB37lITAgP"
      },
      "source": [
        "#@title 2. Calculating Alignment Scores\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpRZ7O0LS5I6"
      },
      "source": [
        "class BahdanauDecoder(nn.Module):\r\n",
        "\r\n",
        "  #Intialize the inputs\r\n",
        "  def __init__(self, hidden_size, output_size, n_layers=1, drop_prob=0.1):\r\n",
        "    super(BahdanauDecoder, self).__init__()\r\n",
        "    self.hidden_size = hidden_size\r\n",
        "    self.output_size = output_size\r\n",
        "    self.n_layers = n_layers\r\n",
        "    self.drop_prob = drop_prob\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\r\n",
        "    \r\n",
        "    self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n",
        "    self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\r\n",
        "    self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\r\n",
        "    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\r\n",
        "    self.dropout = nn.Dropout(self.drop_prob)\r\n",
        "    self.lstm = nn.LSTM(self.hidden_size*2, self.hidden_size, batch_first=True)\r\n",
        "    self.classifier = nn.Linear(self.hidden_size, self.output_size)\r\n",
        "\r\n",
        "  def forward(self, inputs, hidden, encoder_outputs):\r\n",
        "    encoder_outputs = encoder_outputs.squeeze()\r\n",
        "    # Embed input words\r\n",
        "    embedded = self.embedding(inputs).view(1, -1)\r\n",
        "    embedded = self.dropout(embedded)\r\n",
        "       \r\n",
        "    # Calculating Alignment Scores \r\n",
        "    x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\r\n",
        "    alignment_scores = x.bmm(self.weight.unsqueeze(2))  \r\n",
        "\r\n",
        "  # Softmaxing alignment scores to get Attention weights\r\n",
        "    attn_weights = F.softmax(alignment_scores.view(1,-1), dim=1)\r\n",
        "\r\n",
        "  # Multiplying the Attention weights with encoder outputs to get the context vector\r\n",
        "    context_vector = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))  \r\n",
        "\r\n",
        "  # Concatenating context vector with embedded input word\r\n",
        "    output = torch.cat((embedded, context_vector[0]), 1).unsqueeze(0)  \r\n",
        "\r\n",
        "  # Passing the concatenated vector as input to the LSTM cell\r\n",
        "    output, hidden = self.lstm(output, hidden)\r\n",
        "    \r\n",
        "  # Passing the LSTM output through a Linear layer acting as a classifier\r\n",
        "    output = F.log_softmax(self.classifier(output[0]), dim=1)\r\n",
        "    return output, hidden, attn_weights\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFpjrGnyoFd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}